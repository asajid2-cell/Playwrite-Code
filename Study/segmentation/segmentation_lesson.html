<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semantic and Instance Segmentation - CMPUT 328</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Courier New', Consolas, Monaco, monospace;
            background-color: #000000;
            color: #ffffff;
            line-height: 1.6;
            padding: 20px;
            max-width: 1200px;
            margin: 0 auto 80px auto;
        }

        h1, h2, h3, h4, h5, h6 {
            text-align: left;
            margin: 30px 0 15px 0;
            font-weight: bold;
            letter-spacing: 1px;
        }

        h1 {
            font-size: 2.5em;
            border-bottom: 3px solid #ffffff;
            padding-bottom: 10px;
            margin-bottom: 30px;
        }

        h2 {
            font-size: 2em;
            border-bottom: 2px solid #ffffff;
            padding-bottom: 8px;
            margin-top: 50px;
        }

        h3 {
            font-size: 1.5em;
            border-left: 5px solid #ffffff;
            padding-left: 15px;
        }

        h4 {
            font-size: 1.2em;
            text-decoration: underline;
        }

        p {
            margin: 15px 0;
            text-align: left;
        }

        ul, ol {
            margin: 15px 0;
            padding-left: 40px;
            text-align: left;
        }

        li {
            margin: 8px 0;
        }

        code {
            background-color: #1a1a1a;
            color: #ffffff;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', Consolas, Monaco, monospace;
            border: 1px solid #333333;
        }

        pre {
            background-color: #1a1a1a;
            color: #ffffff;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
            border: 1px solid #333333;
            text-align: left;
        }

        pre code {
            background: none;
            border: none;
            padding: 0;
        }
        .codehilite {
            background-color: #1a1a1a;
            border: 1px solid #333333;
            padding: 15px;
            margin: 20px 0;
            overflow-x: auto;
        }

        .codehilite pre {
            margin: 0;
            border: none;
            background: none;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: #0a0a0a;
        }

        th, td {
            border: 1px solid #ffffff;
            padding: 12px;
            text-align: left;
        }

        th {
            background-color: #1a1a1a;
            font-weight: bold;
        }

        tr:nth-child(even) {
            background-color: #0f0f0f;
        }

        .toc {
            background-color: #1a1a1a;
            border: 2px solid #ffffff;
            padding: 20px;
            margin: 30px 0 40px 0;
        }

        .toc h2 {
            margin-top: 0;
            border: none;
        }

        .toc a {
            color: #ffffff;
            text-decoration: none;
            border-bottom: 1px dotted #ffffff;
        }

        .toc a:hover {
            background-color: #ffffff;
            color: #000000;
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            padding: 30px;
            border: 3px solid #ffffff;
            background-color: #0a0a0a;
        }

        .header p {
            font-size: 1.1em;
            margin: 8px 0;
            text-align: center;
        }

        hr {
            border: none;
            border-top: 1px solid #ffffff;
            margin: 40px 0;
        }

        a {
            color: #ffffff;
            text-decoration: underline;
        }

        a:hover {
            background-color: #ffffff;
            color: #000000;
        }

        blockquote {
            border-left: 5px solid #ffffff;
            padding-left: 20px;
            margin: 20px 0;
            background-color: #0a0a0a;
        }

        .action-buttons {
            display: flex;
            gap: 20px;
            margin-top: 50px;
            justify-content: center;
        }

        .action-button {
            background-color: #000000;
            color: #ffffff;
            border: 2px solid #ffffff;
            padding: 15px 25px;
            font-size: 1em;
            cursor: pointer;
            text-transform: uppercase;
            letter-spacing: 1px;
            min-width: 220px;
        }

        .action-button:hover {
            background-color: #ffffff;
            color: #000000;
        }

        .action-button:active {
            transform: translateY(1px);
        }

        .lesson-content {
            margin-top: 30px;
        }

        @media print {
            .action-buttons {
                display: none;
            }

            body {
                background-color: #ffffff;
                color: #000000;
            }

            .header, .toc, pre, code, table, blockquote {
                border-color: #000000;
                color: #000000;
                background-color: #ffffff;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Semantic and Instance Segmentation</h1>
        <p>CMPUT 328 - Assignment 6 Study Guide</p>
        <p>CMPUT 328 - Visual Recognition - Assignment 6</p>
    </div>


    <div class="toc">
        <h2>TABLE OF CONTENTS</h2>
        <ol>
            <li><a href="#1-introduction-to-image-segmentation">Introduction to Image Segmentation</a></li>
            <li><a href="#2-semantic-segmentation">Semantic Segmentation</a></li>
            <li><a href="#3-fully-convolutional-networks-fcn">Fully Convolutional Networks (FCN)</a></li>
            <li><a href="#4-transposed-convolution-upsampling">Transposed Convolution (Upsampling)</a></li>
            <li><a href="#5-u-net-architecture">U-Net Architecture</a></li>
            <li><a href="#6-instance-segmentation">Instance Segmentation</a></li>
            <li><a href="#7-mask-r-cnn">Mask R-CNN</a></li>
            <li><a href="#8-training-strategies">Training Strategies</a></li>
            <li><a href="#9-loss-functions">Loss Functions</a></li>
            <li><a href="#10-evaluation-metrics">Evaluation Metrics</a></li>
            <li><a href="#11-data-preparation-and-labels">Data Preparation and Labels</a></li>
            <li><a href="#12-downsampling-and-upsampling">Downsampling and Upsampling</a></li>
            <li><a href="#13-skip-connections">Skip Connections</a></li>
            <li><a href="#14-state-of-the-art-models">State-of-the-Art Models</a></li>
            <li><a href="#15-implementation-guide">Implementation Guide</a></li>
            <li><a href="#16-common-pitfalls-and-solutions">Common Pitfalls and Solutions</a></li>
        </ol>
    </div>


    <div class="lesson-content">
<h2 id="1-introduction-to-image-segmentation">1. Introduction to Image Segmentation</h2>

<h3 id="what-is-image-segmentation">What is Image Segmentation?</h3>

<p>Image segmentation is the task of partitioning an image into multiple segments or regions, where each pixel is assigned to a specific class or instance.</p>

<h3 id="why-image-segmentation">Why Image Segmentation?</h3>

<p><strong>Applications:</strong></p>

<ul>
<li><strong>Medical imaging</strong>: Tumor detection, organ segmentation</li>
<li><strong>Autonomous driving</strong>: Road detection, pedestrian identification</li>
<li><strong>Satellite imagery</strong>: Land use classification, building detection</li>
<li><strong>Agriculture</strong>: Crop health monitoring, weed detection</li>
<li><strong>Augmented reality</strong>: Background removal, object tracking</li>
</ul>

<h3 id="types-of-segmentation">Types of Segmentation</h3>

<p><strong>1. Semantic Segmentation:</strong></p>

<ul>
<li>Classifies each pixel into a category</li>
<li>Does NOT distinguish between different instances of the same class</li>
<li>Example: All "car" pixels labeled as "car", regardless of which car</li>
</ul>

<p><strong>2. Instance Segmentation:</strong></p>

<ul>
<li>Semantic segmentation + Object detection</li>
<li>Distinguishes between different instances</li>
<li>Example: car₁, car₂, car₃ are labeled separately</li>
</ul>

<p><strong>3. Panoptic Segmentation:</strong></p>

<ul>
<li>Combines semantic and instance segmentation</li>
<li>Every pixel belongs to exactly one segment</li>
</ul>

<hr />

<h2 id="2-semantic-segmentation">2. Semantic Segmentation</h2>

<h3 id="definition">Definition</h3>

<p><strong>Semantic segmentation</strong> is classifying each pixel of an image into a category or class.</p>

<h3 id="how-it-works">How It Works</h3>

<pre><code>Input: RGB Image (H × W × 3)
Output: Label Map (H × W)
</code></pre>

<p>Each pixel in the output corresponds to a class label.</p>

<h3 id="example">Example</h3>

<pre><code>Input Image: Street scene
Classes: road, car, pedestrian, building, sky, tree
Output: Each pixel labeled with one of these classes
</code></pre>

<h3 id="challenges">Challenges</h3>

<ol>
<li><strong>High computational cost</strong>: Processing every pixel</li>
<li><strong>Context understanding</strong>: Need both local and global information</li>
<li><strong>Boundary precision</strong>: Accurate segmentation at object edges</li>
<li><strong>Scale variation</strong>: Objects appear at different sizes</li>
<li><strong>Occlusion</strong>: Objects partially hidden by others</li>
</ol>

<h3 id="differences-from-classification">Differences from Classification</h3>

<table>
<thead>
<tr>
  <th>Aspect</th>
  <th>Classification</th>
  <th>Semantic Segmentation</th>
</tr>
</thead>
<tbody>
<tr>
  <td>Input</td>
  <td>Image</td>
  <td>Image</td>
</tr>
<tr>
  <td>Output</td>
  <td>Single label</td>
  <td>Label per pixel</td>
</tr>
<tr>
  <td>Spatial info</td>
  <td>Lost (after pooling)</td>
  <td>Preserved</td>
</tr>
<tr>
  <td>Complexity</td>
  <td>Lower</td>
  <td>Higher</td>
</tr>
</tbody>
</table>

<hr />

<h2 id="3-fully-convolutional-networks-fcn">3. Fully Convolutional Networks (FCN)</h2>

<h3 id="motivation">Motivation</h3>

<p>Traditional CNNs for classification:</p>

<ul>
<li>Use fully connected layers at the end</li>
<li>Output fixed-size vector</li>
<li>Lose spatial information</li>
</ul>

<p><strong>Problem:</strong> We need spatial output (same size as input)!</p>

<h3 id="fcn-architecture">FCN Architecture</h3>

<p><strong>Key idea:</strong> Replace fully connected layers with convolutional layers</p>

<pre><code>Input Image (H × W × 3)
    ↓
[Conv + Pool] × N  ← Downsampling (encoder)
    ↓
[Conv Transpose] × M  ← Upsampling (decoder)
    ↓
Output Map (H × W × num_classes)
</code></pre>

<h3 id="why-use-fully-convolutional-architecture">Why Use Fully Convolutional Architecture?</h3>

<p><strong>Advantages:</strong></p>

<ol>
<li><strong>Accepts any input size</strong>: No fixed-size requirement</li>
<li><strong>Preserves spatial information</strong>: Output has spatial structure</li>
<li><strong>Efficient</strong>: Shares computation across overlapping regions</li>
<li><strong>End-to-end training</strong>: Learn features and segmentation together</li>
</ol>

<h3 id="converting-fc-to-conv">Converting FC to Conv</h3>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Traditional classification network</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Flatten: [batch, C*H*W]</span>
<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>              <span class="c1"># FC layer</span>

<span class="c1"># Fully convolutional network</span>
<span class="c1"># No flattening!</span>
<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [batch, channels, h, w] preserved</span>
</code></pre>
</div>

<h3 id="output-size-calculation">Output Size Calculation</h3>

<p>After multiple conv and pool operations:</p>

<pre><code>Input: 32×32
After Conv (stride=1, padding=1): 32×32
After MaxPool (2): 16×16
After Conv (stride=1, padding=1): 16×16
After MaxPool (2): 8×8
</code></pre>

<p><strong>Problem:</strong> Output is smaller than input!
<strong>Solution:</strong> Upsampling operations</p>

<hr />

<h2 id="4-transposed-convolution-upsampling">4. Transposed Convolution (Upsampling)</h2>

<h3 id="what-is-transposed-convolution">What is Transposed Convolution?</h3>

<p>Also called <strong>"deconvolution"</strong> or <strong>"upsampling"</strong>:</p>

<ul>
<li>Increases spatial dimensions</li>
<li>Learnable upsampling (unlike simple interpolation)</li>
<li>Inverse operation of convolution (roughly)</li>
</ul>

<h3 id="how-it-works-2">How It Works</h3>

<p><strong>Regular convolution:</strong></p>

<ul>
<li>Slides filter over input</li>
<li>Produces smaller or same-size output</li>
</ul>

<p><strong>Transposed convolution:</strong></p>

<ul>
<li>Slides filter, but expands output</li>
<li>Adds overlap and sums</li>
</ul>

<h3 id="mathematical-intuition">Mathematical Intuition</h3>

<p>For a simple case:</p>

<pre><code>Input = conv(output, kernel, stride)
Output = conv_transpose(input, kernel, stride)
</code></pre>

<h3 id="example-2">Example</h3>

<pre><code>Input: 2×2
Kernel: 3×3
Stride: 2
Output: 5×5  (larger!)
</code></pre>

<p><strong>Process:</strong></p>

<ol>
<li>Insert zeros between input pixels (based on stride)</li>
<li>Apply regular convolution</li>
<li>Result is upsampled output</li>
</ol>

<h3 id="in-pytorch">In PyTorch</h3>

<div class="codehilite">
<pre><span></span><code><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># Input: [batch, 64, 16, 16]</span>
<span class="c1"># Output: [batch, 32, 32, 32]</span>
</code></pre>
</div>

<h3 id="output-size-formula">Output Size Formula</h3>

<pre><code>output_size = (input_size - 1) × stride - 2 × padding + kernel_size + output_padding
</code></pre>

<h3 id="transposed-conv-vs-bilinear-interpolation">Transposed Conv vs Bilinear Interpolation</h3>

<table>
<thead>
<tr>
  <th>Aspect</th>
  <th>Transposed Conv</th>
  <th>Bilinear Interpolation</th>
</tr>
</thead>
<tbody>
<tr>
  <td>Learnable</td>
  <td>Yes</td>
  <td>No</td>
</tr>
<tr>
  <td>Parameters</td>
  <td>Many</td>
  <td>None</td>
</tr>
<tr>
  <td>Quality</td>
  <td>Better (learned)</td>
  <td>Fixed</td>
</tr>
<tr>
  <td>Artifacts</td>
  <td>Checkerboard possible</td>
  <td>Smooth</td>
</tr>
</tbody>
</table>

<p><strong>Best practice:</strong></p>

<ul>
<li>Use bilinear interpolation + Conv for smoother results</li>
<li>Or use transposed conv with careful initialization</li>
</ul>

<hr />

<h2 id="5-u-net-architecture">5. U-Net Architecture</h2>

<h3 id="what-is-u-net">What is U-Net?</h3>

<p><strong>U-Net</strong> is an important architecture for semantic segmentation, especially popular in medical imaging.</p>

<h3 id="architecture-structure">Architecture Structure</h3>

<pre><code>       INPUT (572×572)
           ↓
    ┌──────────────┐
    │   Encoder    │ ← Contracting path (downsampling)
    │   (Down)     │
    └──────┬───────┘
           ↓
    ┌──────────────┐
    │  Bottleneck  │ ← Lowest resolution
    └──────┬───────┘
           ↓
    ┌──────────────┐
    │   Decoder    │ ← Expanding path (upsampling)
    │    (Up)      │   + Skip connections →
    └──────┬───────┘
           ↓
      OUTPUT (388×388)
</code></pre>

<h3 id="key-features">Key Features</h3>

<p><strong>1. Encoder-Decoder Structure:</strong></p>

<ul>
<li><strong>Encoder</strong>: Downsamples, captures context</li>
<li><strong>Decoder</strong>: Upsamples, enables precise localization</li>
</ul>

<p><strong>2. Skip Connections:</strong></p>

<ul>
<li>Connects encoder to decoder at same resolution</li>
<li>Preserves fine-grained details</li>
<li>Helps gradient flow</li>
</ul>

<p><strong>3. Symmetric:</strong></p>

<ul>
<li>Encoder and decoder are mirror images</li>
<li>"U" shape gives the name</li>
</ul>

<h3 id="u-net-block-structure">U-Net Block Structure</h3>

<p><strong>Encoder Block:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Each encoder block</span>
<span class="n">Conv</span><span class="p">(</span><span class="mi">3</span><span class="err">×</span><span class="mi">3</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm</span> <span class="err">→</span> <span class="n">ReLU</span>
<span class="n">Conv</span><span class="p">(</span><span class="mi">3</span><span class="err">×</span><span class="mi">3</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm</span> <span class="err">→</span> <span class="n">ReLU</span>
<span class="n">MaxPool</span><span class="p">(</span><span class="mi">2</span><span class="err">×</span><span class="mi">2</span><span class="p">)</span>  <span class="err">←</span> <span class="n">Downsample</span>
</code></pre>
</div>

<p><strong>Decoder Block:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Each decoder block</span>
<span class="n">ConvTranspose</span><span class="p">(</span><span class="mi">2</span><span class="err">×</span><span class="mi">2</span><span class="p">)</span>  <span class="err">←</span> <span class="n">Upsample</span>
<span class="n">Concatenate</span> <span class="k">with</span> <span class="n">skip</span> <span class="n">connection</span>
<span class="n">Conv</span><span class="p">(</span><span class="mi">3</span><span class="err">×</span><span class="mi">3</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm</span> <span class="err">→</span> <span class="n">ReLU</span>
<span class="n">Conv</span><span class="p">(</span><span class="mi">3</span><span class="err">×</span><span class="mi">3</span><span class="p">)</span> <span class="err">→</span> <span class="n">BatchNorm</span> <span class="err">→</span> <span class="n">ReLU</span>
</code></pre>
</div>

<h3 id="why-u-net-works">Why U-Net Works</h3>

<ol>
<li><strong>Context + Localization</strong>: Encoder captures what, decoder determines where</li>
<li><strong>Skip connections</strong>: Preserve spatial information lost during downsampling</li>
<li><strong>Few parameters</strong>: Works well even with small datasets</li>
<li><strong>Data augmentation friendly</strong>: Can be trained with limited data</li>
</ol>

<h3 id="u-net-vs-fcn">U-Net vs FCN</h3>

<table>
<thead>
<tr>
  <th>Feature</th>
  <th>U-Net</th>
  <th>FCN</th>
</tr>
</thead>
<tbody>
<tr>
  <td>Skip connections</td>
  <td>Yes (concat)</td>
  <td>Yes (add)</td>
</tr>
<tr>
  <td>Structure</td>
  <td>Symmetric U</td>
  <td>Asymmetric</td>
</tr>
<tr>
  <td>Best for</td>
  <td>Medical imaging, small data</td>
  <td>General segmentation</td>
</tr>
<tr>
  <td>Parameters</td>
  <td>Moderate</td>
  <td>Varies</td>
</tr>
</tbody>
</table>

<hr />

<h2 id="6-instance-segmentation">6. Instance Segmentation</h2>

<h3 id="what-is-instance-segmentation">What is Instance Segmentation?</h3>

<p><strong>Instance segmentation</strong> = Semantic segmentation + Object detection</p>

<p><strong>Goal:</strong> Detect and segment each object instance separately</p>

<h3 id="difference-from-semantic-segmentation">Difference from Semantic Segmentation</h3>

<pre><code>Semantic Segmentation:
- All cars labeled as "car"
- Cannot distinguish car₁ from car₂

Instance Segmentation:
- car₁, car₂, car₃ labeled separately
- Each instance has unique ID
</code></pre>

<h3 id="challenges-2">Challenges</h3>

<ol>
<li><strong>Varying number of instances</strong>: Unknown how many objects in image</li>
<li><strong>Overlapping objects</strong>: Objects may occlude each other</li>
<li><strong>Different scales</strong>: Objects appear at different sizes</li>
<li><strong>Computational cost</strong>: More complex than semantic segmentation</li>
</ol>

<h3 id="approaches">Approaches</h3>

<p><strong>1. Detect-then-Segment:</strong></p>

<ul>
<li>First detect bounding boxes</li>
<li>Then segment within each box</li>
<li>Example: Mask R-CNN</li>
</ul>

<p><strong>2. Segment-then-Detect:</strong></p>

<ul>
<li>First generate segmentation proposals</li>
<li>Then cluster into instances</li>
</ul>

<p><strong>3. Bottom-up:</strong></p>

<ul>
<li>Segment all pixels</li>
<li>Group pixels into instances</li>
<li>Example: Associative embedding</li>
</ul>

<hr />

<h2 id="7-mask-r-cnn">7. Mask R-CNN</h2>

<h3 id="overview">Overview</h3>

<p><strong>Mask R-CNN</strong> extends Faster R-CNN by adding a branch for predicting segmentation masks on each Region of Interest (RoI).</p>

<h3 id="architecture">Architecture</h3>

<pre><code>Input Image
    ↓
┌─────────────────────┐
│  Backbone (ResNet)  │ ← Feature extraction
└─────────┬───────────┘
          ↓
┌─────────────────────┐
│  Region Proposal    │ ← Propose object locations
│  Network (RPN)      │
└─────────┬───────────┘
          ↓
┌─────────────────────┐
│   RoI Align         │ ← Extract features for each proposal
└─────────┬───────────┘
          ↓
    ┌────┴────┐
    ↓         ↓         ↓
┌────────┐ ┌────────┐ ┌────────┐
│  Box   │ │ Class  │ │  Mask  │ ← Three parallel heads
│Regress │ │Predict │ │ Predict│
└────────┘ └────────┘ └────────┘
</code></pre>

<h3 id="key-components">Key Components</h3>

<p><strong>1. Backbone:</strong></p>

<ul>
<li>Usually ResNet-50 or ResNet-101</li>
<li>Extracts features from input image</li>
<li>Output: Feature maps</li>
</ul>

<p><strong>2. Region Proposal Network (RPN):</strong></p>

<ul>
<li>Proposes candidate object bounding boxes</li>
<li>Learned, not hand-crafted</li>
</ul>

<p><strong>3. RoI Align:</strong></p>

<ul>
<li>Extracts features for each proposal</li>
<li>Improves on RoI Pooling (no quantization)</li>
<li>Preserves spatial alignment</li>
</ul>

<p><strong>4. Three Heads:</strong></p>

<ul>
<li><strong>Classification</strong>: What is the object?</li>
<li><strong>Bounding box regression</strong>: Where exactly is it?</li>
<li><strong>Mask prediction</strong>: What are its pixel-wise boundaries?</li>
</ul>

<h3 id="mask-head">Mask Head</h3>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Mask head architecture</span>
<span class="c1"># For each RoI:</span>
<span class="n">Conv</span><span class="p">(</span><span class="mi">3</span><span class="err">×</span><span class="mi">3</span><span class="p">)</span> <span class="err">×</span> <span class="mi">4</span>  <span class="err">←</span> <span class="n">Feature</span> <span class="n">extraction</span>
<span class="n">ConvTranspose</span><span class="p">(</span><span class="mi">2</span><span class="err">×</span><span class="mi">2</span><span class="p">)</span>  <span class="err">←</span> <span class="n">Upsample</span>
<span class="n">Conv</span><span class="p">(</span><span class="mi">1</span><span class="err">×</span><span class="mi">1</span><span class="p">)</span>  <span class="err">←</span> <span class="n">num_classes</span> <span class="n">masks</span>

<span class="c1"># Output: [num_classes, 28, 28]</span>
<span class="c1"># One binary mask per class</span>
</code></pre>
</div>

<h3 id="roi-align-vs-roi-pool">RoI Align vs RoI Pool</h3>

<p><strong>RoI Pool (Faster R-CNN):</strong></p>

<ul>
<li>Quantizes coordinates to integer</li>
<li>Loses spatial precision</li>
<li>Bad for segmentation</li>
</ul>

<p><strong>RoI Align (Mask R-CNN):</strong></p>

<ul>
<li>Uses bilinear interpolation</li>
<li>No quantization</li>
<li>Preserves exact spatial locations</li>
<li><strong>Critical for mask quality!</strong></li>
</ul>

<h3 id="training-mask-r-cnn">Training Mask R-CNN</h3>

<p><strong>Multi-task loss:</strong></p>

<pre><code>L_total = L_cls + L_box + L_mask

Where:
- L_cls: Classification loss (cross-entropy)
- L_box: Bounding box regression loss (smooth L1)
- L_mask: Mask loss (binary cross-entropy per pixel)
</code></pre>

<p><strong>Important:</strong> Mask loss only computed for the true class (not all classes)</p>

<h3 id="mask-r-cnn-performance">Mask R-CNN Performance</h3>

<p><strong>State-of-the-art results on COCO:</strong></p>

<ul>
<li>37.1 AP (Average Precision) for instance segmentation</li>
<li>39.8 AP for object detection</li>
</ul>

<hr />

<h2 id="8-training-strategies">8. Training Strategies</h2>

<h3 id="data-augmentation">Data Augmentation</h3>

<p><strong>Essential augmentations for segmentation:</strong></p>

<ol>
<li><strong>Random crop and resize</strong></li>
</ol>

<div class="codehilite">
<pre><span></span><code><span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span>
</code></pre>
</div>

<ol start="2">
<li><strong>Horizontal flip</strong> (must flip both image and mask!)</li>
</ol>

<div class="codehilite">
<pre><span></span><code><span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</code></pre>
</div>

<ol start="3">
<li><strong>Color jitter</strong> (image only)</li>
</ol>

<div class="codehilite">
<pre><span></span><code><span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre>
</div>

<ol start="4">
<li><strong>Random rotation</strong> (both image and mask)</li>
</ol>

<div class="codehilite">
<pre><span></span><code><span class="n">angle</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">angle</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">angle</span><span class="p">)</span>
</code></pre>
</div>

<p><strong>CRITICAL:</strong> Always apply same geometric transformation to both image and mask!</p>

<h3 id="training-pipeline">Training Pipeline</h3>

<div class="codehilite">
<pre><span></span><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">masks</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Forward pass</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

        <span class="c1"># Compute loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Backward pass</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Validate</span>
    <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="learning-rate-strategies">Learning Rate Strategies</h3>

<p><strong>1. Warm-up then decay:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Start small, increase, then decay</span>
<span class="n">epochs</span><span class="p">:</span> <span class="mi">0</span><span class="o">-</span><span class="mi">5</span><span class="p">:</span> <span class="n">linear</span> <span class="n">increase</span>
<span class="n">epochs</span><span class="p">:</span> <span class="mi">5</span><span class="o">-</span><span class="mi">50</span><span class="p">:</span> <span class="n">cosine</span> <span class="n">decay</span>
</code></pre>
</div>

<p><strong>2. Poly learning rate:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">lr</span> <span class="o">=</span> <span class="n">base_lr</span> <span class="err">×</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="nb">iter</span><span class="o">/</span><span class="n">max_iter</span><span class="p">)</span><span class="o">^</span><span class="n">power</span>
</code></pre>
</div>

<p><strong>3. Step decay:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Reduce by factor at milestones</span>
<span class="n">milestones</span> <span class="o">=</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">90</span><span class="p">]</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span>
</code></pre>
</div>

<h3 id="batch-size-considerations">Batch Size Considerations</h3>

<ul>
<li><strong>Larger batch</strong>: More stable, but needs more memory</li>
<li><strong>Typical range</strong>: 8-32 for segmentation (depends on image size)</li>
<li><strong>Gradient accumulation</strong>: Simulate larger batch with limited GPU</li>
</ul>

<h3 id="class-imbalance">Class Imbalance</h3>

<p><strong>Problem:</strong> Some classes appear much more than others (e.g., background vs rare object)</p>

<p><strong>Solutions:</strong></p>

<ol>
<li><strong>Weighted loss</strong>: Weight rare classes higher</li>
<li><strong>Focal loss</strong>: Focus on hard examples</li>
<li><strong>Data sampling</strong>: Oversample rare classes</li>
</ol>

<hr />

<h2 id="9-loss-functions">9. Loss Functions</h2>

<h3 id="cross-entropy-loss">Cross-Entropy Loss</h3>

<p><strong>Standard for semantic segmentation:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

<span class="c1"># outputs: [batch, num_classes, H, W]</span>
<span class="c1"># targets: [batch, H, W] (class indices)</span>
</code></pre>
</div>

<p><strong>Formula:</strong></p>

<pre><code>L_CE = -Σ_pixels Σ_classes y_c × log(p_c)
</code></pre>

<h3 id="weighted-cross-entropy">Weighted Cross-Entropy</h3>

<p><strong>For class imbalance:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Compute class weights (inverse frequency)</span>
<span class="n">class_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">class_weights</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="dice-loss">Dice Loss</h3>

<p><strong>Popular in medical imaging:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">dice_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="n">smooth</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">pred_flat</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">target_flat</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">intersection</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_flat</span> <span class="o">*</span> <span class="n">target_flat</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="n">dice</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">intersection</span> <span class="o">+</span> <span class="n">smooth</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
        <span class="n">pred_flat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">target_flat</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">smooth</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dice</span>
</code></pre>
</div>

<p><strong>Advantages:</strong></p>

<ul>
<li>Handles class imbalance well</li>
<li>Directly optimizes overlap</li>
<li>Works for binary and multi-class</li>
</ul>

<h3 id="focal-loss">Focal Loss</h3>

<p><strong>Focuses on hard examples:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">focal_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="n">ce_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">p_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">ce_loss</span><span class="p">)</span>
    <span class="n">focal</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_t</span><span class="p">)</span> <span class="o">**</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">ce_loss</span>
    <span class="k">return</span> <span class="n">focal</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre>
</div>

<p><strong>Why it works:</strong></p>

<ul>
<li>Easy examples (p_t near 1) get down-weighted</li>
<li>Hard examples (p_t near 0) dominate the loss</li>
<li>Prevents easy background from overwhelming</li>
</ul>

<h3 id="combined-loss">Combined Loss</h3>

<p><strong>Often best to combine losses:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">total_loss</span> <span class="o">=</span> <span class="n">ce_loss</span> <span class="o">+</span> <span class="n">dice_loss</span>
<span class="c1"># or</span>
<span class="n">total_loss</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">ce_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">dice_loss</span>
</code></pre>
</div>

<hr />

<h2 id="10-evaluation-metrics">10. Evaluation Metrics</h2>

<h3 id="pixel-accuracy">Pixel Accuracy</h3>

<p><strong>Simplest metric:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct_pixels</span> <span class="o">/</span> <span class="n">total_pixels</span>
</code></pre>
</div>

<p><strong>Problem:</strong> Not good for class imbalance</p>

<ul>
<li>If 90% background, predicting all background gives 90% accuracy!</li>
</ul>

<h3 id="mean-iou-intersection-over-union">Mean IoU (Intersection over Union)</h3>

<p><strong>Most common metric for segmentation:</strong></p>

<pre><code>IoU = (Prediction ∩ Ground Truth) / (Prediction ∪ Ground Truth)
</code></pre>

<p><strong>Per class:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_iou</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">class_id</span><span class="p">):</span>
    <span class="n">pred_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">class_id</span><span class="p">)</span>
    <span class="n">target_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">target</span> <span class="o">==</span> <span class="n">class_id</span><span class="p">)</span>

    <span class="n">intersection</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_mask</span> <span class="o">&amp;</span> <span class="n">target_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">union</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_mask</span> <span class="o">|</span> <span class="n">target_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="n">iou</span> <span class="o">=</span> <span class="n">intersection</span> <span class="o">/</span> <span class="p">(</span><span class="n">union</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">iou</span>
</code></pre>
</div>

<p><strong>Mean IoU:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">mean_iou</span> <span class="o">=</span> <span class="n">mean</span><span class="p">([</span><span class="n">iou_class_1</span><span class="p">,</span> <span class="n">iou_class_2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">iou_class_n</span><span class="p">])</span>
</code></pre>
</div>

<h3 id="dice-coefficient">Dice Coefficient</h3>

<p><strong>Alternative to IoU:</strong></p>

<pre><code>Dice = 2 × |Prediction ∩ Ground Truth| / (|Prediction| + |Ground Truth|)
</code></pre>

<p><strong>Relationship to IoU:</strong></p>

<pre><code>Dice = 2 × IoU / (1 + IoU)
</code></pre>

<h3 id="for-instance-segmentation">For Instance Segmentation</h3>

<p><strong>Average Precision (AP):</strong></p>

<ul>
<li>Computed at different IoU thresholds</li>
<li>AP50: IoU threshold = 0.5</li>
<li>AP75: IoU threshold = 0.75</li>
<li>AP: Average over thresholds 0.5 to 0.95</li>
</ul>

<p><strong>COCO metrics:</strong></p>

<ul>
<li>AP: Primary metric</li>
<li>AP50, AP75: At specific thresholds</li>
<li>AP<em>S, AP</em>M, AP_L: For small, medium, large objects</li>
</ul>

<hr />

<h2 id="11-data-preparation-and-labels">11. Data Preparation and Labels</h2>

<h3 id="label-format-for-semantic-segmentation">Label Format for Semantic Segmentation</h3>

<p><strong>Image-like format:</strong></p>

<pre><code>Training image: RGB (H × W × 3)
Label image: Grayscale (H × W)

Each pixel value = class index
Example:
- 0: background
- 1: car
- 2: person
- 3: road
</code></pre>

<h3 id="creating-label-images">Creating Label Images</h3>

<div class="codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># Create label image (same size as input)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

<span class="c1"># Fill in labels (example: all pixels in certain region)</span>
<span class="n">label</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">200</span><span class="p">,</span> <span class="mi">100</span><span class="p">:</span><span class="mi">200</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Class 1 (e.g., car)</span>
<span class="n">label</span><span class="p">[</span><span class="mi">50</span><span class="p">:</span><span class="mi">150</span><span class="p">,</span> <span class="mi">50</span><span class="p">:</span><span class="mi">150</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>    <span class="c1"># Class 2 (e.g., person)</span>

<span class="c1"># Save as image</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;label.png&#39;</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="dataset-structure">Dataset Structure</h3>

<pre><code>dataset/
├── images/
│   ├── train/
│   │   ├── img1.jpg
│   │   ├── img2.jpg
│   └── val/
│       ├── img3.jpg
└── labels/
    ├── train/
    │   ├── img1.png
    │   ├── img2.png
    └── val/
        ├── img3.png
</code></pre>

<h3 id="pytorch-dataset">PyTorch Dataset</h3>

<div class="codehilite">
<pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">SegmentationDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_dir</span><span class="p">,</span> <span class="n">label_dir</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_dir</span> <span class="o">=</span> <span class="n">image_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_dir</span> <span class="o">=</span> <span class="n">label_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">images</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">image_dir</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">label_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">label_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>
</code></pre>
</div>

<h3 id="important-considerations">Important Considerations</h3>

<ol>
<li><strong>Label images must be single-channel</strong> (grayscale)</li>
<li><strong>No compression artifacts</strong>: Save as PNG, not JPEG</li>
<li><strong>Same dimensions</strong>: Label must match image size</li>
<li><strong>Class indices start from 0</strong></li>
<li><strong>Background typically class 0</strong></li>
</ol>

<hr />

<h2 id="12-downsampling-and-upsampling">12. Downsampling and Upsampling</h2>

<h3 id="why-downsample">Why Downsample?</h3>

<p><strong>Computational efficiency:</strong></p>

<ul>
<li>Processing smaller feature maps is faster</li>
<li>Reduces memory usage</li>
<li>Enables deeper networks</li>
</ul>

<p><strong>Larger receptive field:</strong></p>

<ul>
<li>Each pixel "sees" more of the image</li>
<li>Captures more context</li>
</ul>

<p><strong>Does NOT hurt segmentation accuracy when combined with upsampling!</strong></p>

<h3 id="downsampling-methods">Downsampling Methods</h3>

<p><strong>1. Max Pooling:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># 32×32 → 16×16</span>
</code></pre>
</div>

<ul>
<li>Preserves strong activations</li>
<li>No learnable parameters</li>
<li>Information loss</li>
</ul>

<p><strong>2. Strided Convolution:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># 32×32 → 16×16</span>
</code></pre>
</div>

<ul>
<li>Learnable downsampling</li>
<li>More parameters</li>
<li>Better than pooling in some cases</li>
</ul>

<h3 id="upsampling-methods">Upsampling Methods</h3>

<p><strong>1. Transposed Convolution (see Section 4):</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre>
</div>

<ul>
<li>Learnable</li>
<li>Can produce checkerboard artifacts</li>
</ul>

<p><strong>2. Bilinear Interpolation:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre>
</div>

<ul>
<li>Fixed, not learnable</li>
<li>Smooth results</li>
<li>No artifacts</li>
</ul>

<p><strong>3. Bilinear + Conv (Recommended):</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
</code></pre>
</div>

<ul>
<li>Combines smoothness + learning</li>
<li>Avoids checkerboard artifacts</li>
<li>Often works better than transposed conv</li>
</ul>

<h3 id="downsampling-upsampling-pipeline">Downsampling-Upsampling Pipeline</h3>

<pre><code>Input: 256×256
    ↓ Conv + Pool
    128×128
    ↓ Conv + Pool
    64×64
    ↓ Conv + Pool
    32×32  ← Bottleneck (most compressed)
    ↓ Upsample + Conv
    64×64
    ↓ Upsample + Conv
    128×128
    ↓ Upsample + Conv
Output: 256×256
</code></pre>

<hr />

<h2 id="13-skip-connections">13. Skip Connections</h2>

<h3 id="what-are-skip-connections">What are Skip Connections?</h3>

<p><strong>Direct connections from encoder to decoder at same resolution:</strong></p>

<pre><code>Encoder              Decoder

32×32 ─────────────→ 32×32 (concat or add)
  ↓                     ↑
16×16 ─────────────→ 16×16
  ↓                     ↑
 8×8  ─────────────→  8×8
  ↓                     ↑
 4×4  ←─ bottleneck
</code></pre>

<h3 id="why-skip-connections">Why Skip Connections?</h3>

<p><strong>1. Preserve spatial details:</strong></p>

<ul>
<li>Downsampling loses fine-grained information</li>
<li>Skip connections bring it back</li>
</ul>

<p><strong>2. Better gradient flow:</strong></p>

<ul>
<li>Easier for gradients to flow during backprop</li>
<li>Speeds up training</li>
</ul>

<p><strong>3. Combine features:</strong></p>

<ul>
<li>Low-level features (edges) + High-level features (semantics)</li>
<li>Best of both worlds</li>
</ul>

<h3 id="types-of-skip-connections">Types of Skip Connections</h3>

<p><strong>1. Concatenation (U-Net style):</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Encoder output: [batch, 64, 32, 32]</span>
<span class="c1"># Decoder output: [batch, 64, 32, 32]</span>
<span class="c1"># Concatenate along channel dimension</span>
<span class="n">skip</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">encoder_out</span><span class="p">,</span> <span class="n">decoder_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Result: [batch, 128, 32, 32]</span>
</code></pre>
</div>

<p><strong>2. Addition (ResNet style):</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Both must have same channels</span>
<span class="n">skip</span> <span class="o">=</span> <span class="n">encoder_out</span> <span class="o">+</span> <span class="n">decoder_out</span>
<span class="c1"># Result: [batch, 64, 32, 32]</span>
</code></pre>
</div>

<h3 id="implementation">Implementation</h3>

<div class="codehilite">
<pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">UNetWithSkips</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Encoder</span>
        <span class="n">e1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>      <span class="c1"># 256×256</span>
        <span class="n">e2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc2</span><span class="p">(</span><span class="n">e1</span><span class="p">)</span>     <span class="c1"># 128×128</span>
        <span class="n">e3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc3</span><span class="p">(</span><span class="n">e2</span><span class="p">)</span>     <span class="c1"># 64×64</span>
        <span class="n">e4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc4</span><span class="p">(</span><span class="n">e3</span><span class="p">)</span>     <span class="c1"># 32×32</span>

        <span class="c1"># Bottleneck</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span><span class="p">(</span><span class="n">e4</span><span class="p">)</span>  <span class="c1"># 16×16</span>

        <span class="c1"># Decoder with skip connections</span>
        <span class="n">d4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec4</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="n">e4</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>    <span class="c1"># 32×32</span>
        <span class="n">d3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec3</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d4</span><span class="p">,</span> <span class="n">e3</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>   <span class="c1"># 64×64</span>
        <span class="n">d2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec2</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d3</span><span class="p">,</span> <span class="n">e2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>   <span class="c1"># 128×128</span>
        <span class="n">d1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec1</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d2</span><span class="p">,</span> <span class="n">e1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>   <span class="c1"># 256×256</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final</span><span class="p">(</span><span class="n">d1</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="skip-connections-with-vs-without">Skip Connections: With vs Without</h3>

<table>
<thead>
<tr>
  <th>Aspect</th>
  <th>Without Skips</th>
  <th>With Skips</th>
</tr>
</thead>
<tbody>
<tr>
  <td>Boundary quality</td>
  <td>Blurry</td>
  <td>Sharp</td>
</tr>
<tr>
  <td>Training speed</td>
  <td>Slower</td>
  <td>Faster</td>
</tr>
<tr>
  <td>Gradient flow</td>
  <td>Difficult</td>
  <td>Easy</td>
</tr>
<tr>
  <td>Fine details</td>
  <td>Lost</td>
  <td>Preserved</td>
</tr>
</tbody>
</table>

<p><strong>Rule of thumb:</strong> Always use skip connections for segmentation!</p>

<hr />

<h2 id="14-state-of-the-art-models">14. State-of-the-Art Models</h2>

<h3 id="deeplab-v3">DeepLab v3+</h3>

<p><strong>Key innovations:</strong></p>

<ol>
<li><strong>Atrous (dilated) convolution</strong>: Enlarges receptive field without pooling</li>
<li><strong>Atrous Spatial Pyramid Pooling (ASPP)</strong>: Multi-scale context</li>
<li><strong>Encoder-decoder with skip connections</strong></li>
</ol>

<p><strong>Performance:</strong> State-of-the-art on PASCAL VOC, Cityscapes</p>

<h3 id="pspnet-pyramid-scene-parsing-network">PSPNet (Pyramid Scene Parsing Network)</h3>

<p><strong>Key innovation:</strong></p>

<ul>
<li><strong>Pyramid pooling module</strong>: Captures context at multiple scales</li>
<li>Global average pooling at different scales</li>
<li>Concatenate multi-scale features</li>
</ul>

<h3 id="hrnet-high-resolution-network">HRNet (High-Resolution Network)</h3>

<p><strong>Key innovation:</strong></p>

<ul>
<li>Maintains high-resolution representations throughout</li>
<li>Parallel multi-resolution branches</li>
<li>Repeated multi-scale fusion</li>
</ul>

<p><strong>Advantage:</strong> Better for tasks requiring fine details</p>

<h3 id="swin-unetr">Swin-UNETR</h3>

<p><strong>Recent advancement:</strong></p>

<ul>
<li>Uses Swin Transformer as encoder</li>
<li>U-Net style decoder</li>
<li>State-of-the-art for medical imaging</li>
</ul>

<h3 id="sam-segment-anything-model">SAM (Segment Anything Model)</h3>

<p><strong>Foundation model for segmentation:</strong></p>

<ul>
<li>Trained on 11 million images, 1 billion masks</li>
<li>Zero-shot segmentation</li>
<li>Interactive (user prompts)</li>
<li>Can segment anything with minimal guidance</li>
</ul>

<p><strong>Use cases:</strong></p>

<ul>
<li>Quick annotation</li>
<li>Transfer learning</li>
<li>General-purpose segmentation</li>
</ul>

<hr />

<h2 id="15-implementation-guide">15. Implementation Guide</h2>

<h3 id="complete-u-net-implementation">Complete U-Net Implementation</h3>

<div class="codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">UNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">21</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Bottleneck</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>

        <span class="c1"># Decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upconv4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dec4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">upconv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dec3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">upconv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dec2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">upconv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dec1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

        <span class="c1"># Final layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">conv_block</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Encoder</span>
        <span class="n">e1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">e2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">e1</span><span class="p">))</span>
        <span class="n">e3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">e2</span><span class="p">))</span>
        <span class="n">e4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc4</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">e3</span><span class="p">))</span>

        <span class="c1"># Bottleneck</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">e4</span><span class="p">))</span>

        <span class="c1"># Decoder</span>
        <span class="n">d4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upconv4</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="n">d4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d4</span><span class="p">,</span> <span class="n">e4</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">d4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec4</span><span class="p">(</span><span class="n">d4</span><span class="p">)</span>

        <span class="n">d3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upconv3</span><span class="p">(</span><span class="n">d4</span><span class="p">)</span>
        <span class="n">d3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d3</span><span class="p">,</span> <span class="n">e3</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">d3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec3</span><span class="p">(</span><span class="n">d3</span><span class="p">)</span>

        <span class="n">d2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upconv2</span><span class="p">(</span><span class="n">d3</span><span class="p">)</span>
        <span class="n">d2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d2</span><span class="p">,</span> <span class="n">e2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">d2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec2</span><span class="p">(</span><span class="n">d2</span><span class="p">)</span>

        <span class="n">d1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upconv1</span><span class="p">(</span><span class="n">d2</span><span class="p">)</span>
        <span class="n">d1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d1</span><span class="p">,</span> <span class="n">e1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">d1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec1</span><span class="p">(</span><span class="n">d1</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final</span><span class="p">(</span><span class="n">d1</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="training-loop">Training Loop</h3>

<div class="codehilite">
<pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">masks</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Forward</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Backward</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">total_iou</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">masks</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Compute IoU</span>
            <span class="n">iou</span> <span class="o">=</span> <span class="n">compute_mean_iou</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
            <span class="n">total_iou</span> <span class="o">+=</span> <span class="n">iou</span>

    <span class="k">return</span> <span class="n">total_iou</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_mean_iou</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
    <span class="n">ious</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="n">pred_cls</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">)</span>
        <span class="n">target_cls</span> <span class="o">=</span> <span class="p">(</span><span class="n">target</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">)</span>

        <span class="n">intersection</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_cls</span> <span class="o">&amp;</span> <span class="n">target_cls</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">union</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_cls</span> <span class="o">|</span> <span class="n">target_cls</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">union</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ious</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ious</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">intersection</span> <span class="o">/</span> <span class="n">union</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="c1"># Mean IoU (ignoring NaN for classes not in ground truth)</span>
    <span class="n">ious</span> <span class="o">=</span> <span class="p">[</span><span class="n">iou</span> <span class="k">for</span> <span class="n">iou</span> <span class="ow">in</span> <span class="n">ious</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">iou</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ious</span><span class="p">)</span> <span class="k">if</span> <span class="n">ious</span> <span class="k">else</span> <span class="mf">0.0</span>
</code></pre>
</div>

<h3 id="complete-training-script">Complete Training Script</h3>

<div class="codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1"># Model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">UNet</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Loss and optimizer</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>

<span class="c1"># Training</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">best_iou</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">val_iou</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span>

    <span class="c1"># Update learning rate</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">val_iou</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val IoU: </span><span class="si">{</span><span class="n">val_iou</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Save best model</span>
    <span class="k">if</span> <span class="n">val_iou</span> <span class="o">&gt;</span> <span class="n">best_iou</span><span class="p">:</span>
        <span class="n">best_iou</span> <span class="o">=</span> <span class="n">val_iou</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;best_unet.pt&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saved best model with IoU: </span><span class="si">{</span><span class="n">best_iou</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre>
</div>

<hr />

<h2 id="16-common-pitfalls-and-solutions">16. Common Pitfalls and Solutions</h2>

<h3 id="pitfall-1-wrong-label-format">Pitfall 1: Wrong Label Format</h3>

<p><strong>Wrong:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Labels as one-hot encoded (H, W, num_classes)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</code></pre>
</div>

<p><strong>Correct:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Labels as class indices (H, W)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_id</span>  <span class="c1"># 0 to num_classes-1</span>
</code></pre>
</div>

<h3 id="pitfall-2-augmentation-mismatch">Pitfall 2: Augmentation Mismatch</h3>

<p><strong>Wrong:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Augment image and mask separately</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  <span class="c1"># Random crop/flip</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>    <span class="c1"># Different random crop/flip!</span>
</code></pre>
</div>

<p><strong>Correct:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Apply SAME transformation to both</span>
<span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">32</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="pitfall-3-size-mismatch">Pitfall 3: Size Mismatch</h3>

<p><strong>Problem:</strong> Output size doesn't match input size</p>

<p><strong>Debug:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre>
</div>

<p><strong>Solution:</strong> Adjust padding/stride in upsampling layers</p>

<h3 id="pitfall-4-class-imbalance-ignored">Pitfall 4: Class Imbalance Ignored</h3>

<p><strong>Wrong:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Treat all classes equally</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</code></pre>
</div>

<p><strong>Correct:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Weight rare classes higher</span>
<span class="n">class_weights</span> <span class="o">=</span> <span class="n">compute_class_weights</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">class_weights</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="pitfall-5-not-using-skip-connections">Pitfall 5: Not Using Skip Connections</h3>

<p><strong>Wrong:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Encoder-decoder without skips</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Blurry boundaries!</span>
</code></pre>
</div>

<p><strong>Correct:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># With skip connections</span>
<span class="n">e1</span><span class="p">,</span> <span class="n">e2</span><span class="p">,</span> <span class="n">e3</span><span class="p">,</span> <span class="n">e4</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">e1</span><span class="p">,</span> <span class="n">e2</span><span class="p">,</span> <span class="n">e3</span><span class="p">,</span> <span class="n">e4</span><span class="p">)</span>  <span class="c1"># Sharp boundaries!</span>
</code></pre>
</div>

<h3 id="pitfall-6-wrong-evaluation-mode">Pitfall 6: Wrong Evaluation Mode</h3>

<p><strong>Wrong:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="c1"># Not setting eval mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># or not calling eval()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</code></pre>
</div>

<p><strong>Correct:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># CRITICAL!</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="pitfall-7-memory-issues">Pitfall 7: Memory Issues</h3>

<p><strong>Problem:</strong> Out of memory with high-resolution images</p>

<p><strong>Solutions:</strong></p>

<ol>
<li>Reduce batch size</li>
<li>Use gradient checkpointing</li>
<li>Crop images into patches</li>
<li>Use mixed precision training</li>
</ol>

<div class="codehilite">
<pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">torch.cuda.amp</span><span class="w"> </span><span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">()</span>

<span class="k">with</span> <span class="n">autocast</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>

<span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</code></pre>
</div>

<h3 id="pitfall-8-ignoring-boundary-pixels">Pitfall 8: Ignoring Boundary Pixels</h3>

<p><strong>Problem:</strong> Predictions at image boundaries are poor</p>

<p><strong>Solution:</strong> Use padding or valid convolutions carefully</p>

<h3 id="pitfall-9-oversmoothing">Pitfall 9: Oversmoothing</h3>

<p><strong>Problem:</strong> Predictions are blurry</p>

<p><strong>Causes:</strong></p>

<ul>
<li>Too many pooling layers</li>
<li>No skip connections</li>
<li>Over-regularization</li>
</ul>

<p><strong>Solutions:</strong></p>

<ul>
<li>Add skip connections</li>
<li>Use fewer pooling layers</li>
<li>Reduce dropout</li>
</ul>

<h3 id="pitfall-10-not-visualizing-predictions">Pitfall 10: Not Visualizing Predictions</h3>

<p><strong>Always visualize during training:</strong></p>

<div class="codehilite">
<pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">visualize_predictions</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Ground Truth&#39;</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Prediction&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre>
</div>

<hr />

<h2 id="summary">Summary</h2>

<h3 id="key-takeaways">Key Takeaways</h3>

<ol>
<li><strong>Semantic segmentation</strong> classifies each pixel into a class</li>
<li><strong>Instance segmentation</strong> distinguishes individual object instances</li>
<li><strong>Fully convolutional networks</strong> preserve spatial information</li>
<li><strong>U-Net</strong> architecture with skip connections is highly effective</li>
<li><strong>Transposed convolution</strong> or bilinear interpolation for upsampling</li>
<li><strong>Skip connections</strong> preserve fine-grained details</li>
<li><strong>Mask R-CNN</strong> extends Faster R-CNN for instance segmentation</li>
<li><strong>Data augmentation</strong> must be applied to both image and mask</li>
<li><strong>Mean IoU</strong> is the standard evaluation metric</li>
<li><strong>Class imbalance</strong> requires weighted loss or focal loss</li>
</ol>

<h3 id="typical-results">Typical Results</h3>

<table>
<thead>
<tr>
  <th>Task</th>
  <th>Dataset</th>
  <th>Metric</th>
  <th>Good Result</th>
</tr>
</thead>
<tbody>
<tr>
  <td>Semantic Seg</td>
  <td>PASCAL VOC</td>
  <td>mIoU</td>
  <td>75-85%</td>
</tr>
<tr>
  <td>Semantic Seg</td>
  <td>Cityscapes</td>
  <td>mIoU</td>
  <td>75-80%</td>
</tr>
<tr>
  <td>Instance Seg</td>
  <td>COCO</td>
  <td>AP</td>
  <td>35-40%</td>
</tr>
</tbody>
</table>

<h3 id="next-steps">Next Steps</h3>

<ul>
<li>Implement U-Net from scratch</li>
<li>Train on a small dataset (e.g., flower segmentation)</li>
<li>Experiment with different loss functions</li>
<li>Try skip connections vs no skip connections</li>
<li>Visualize learned features</li>
<li>Explore state-of-the-art models (DeepLab, PSPNet)</li>
</ul>

<hr />

<h2 id="references">References</h2>

<ul>
<li><a href="https://arxiv.org/abs/1505.04597">U-Net: Convolutional Networks for Biomedical Image Segmentation</a></li>
<li><a href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a></li>
<li><a href="https://arxiv.org/abs/1411.4038">Fully Convolutional Networks for Semantic Segmentation</a></li>
<li><a href="https://arxiv.org/abs/1606.00915">DeepLab: Semantic Image Segmentation</a></li>
<li><a href="https://arxiv.org/abs/2304.02643">Segment Anything Model (SAM)</a></li>
<li><a href="https://d2l.ai/chapter_computer-vision/semantic-segmentation-and-dataset.html">D2L.ai - Semantic Segmentation</a></li>
<li><a href="https://d2l.ai/chapter_computer-vision/transposed-conv.html">D2L.ai - Transposed Convolution</a></li>
</ul>

<hr />

<p><strong>End of Lesson</strong></p>

    </div>

    <div class="action-buttons">
        <button class="action-button" onclick="exportToPDF()">EXPORT AS PDF</button>
        <a href="Semantic_Instance_Segmentation.apkg" download class="action-button">DOWNLOAD ANKI DECK</a>
    </div>

    <script>
        function exportToPDF() {
            window.print();
        }
    </script>
</body>
</html>
